
1.--

Learning Objectives--

-
Learning Objectives
In this lesson you will learn about:
Regression Algorithms 
Model Evaluation 
Model Evaluation: Overfitting & Underfitting
Understanding Different Evaluation Models
Simple Linear Regression
---------------------------------------------------------------------------

2.--Intro to Regression 

The question is, "Given this dataset, can we predict the Co2 emission of a car using
other fields, such as EngineSize or Cylinders?"

We can use regression methods to predict a continuous value, such as CO2 Emission, using
some other variables.
--
Regression::::

-"Indeed, regression is the process of predicting a continuous value.
In regression there are two types of variables: a dependent variable and one or more independent
variables."

The dependent variable can be seen as the "state", "target" or "final goal" we study
and try to predict, and the independent variables, also known as explanatory variables, can be
seen as the "causes" of those "states".
-
The independent variables are shown conventionally by x; and the dependent variable is notated
by y.
A regression model relates y, or the dependent variable, to a function of x, i.e., the independent
variables.
The key point in the regression is that our dependent value should be continuous, and
cannot be a discreet value.
However, the independent variable or variables can be measured on either a categorical or
continuous measurement scale.
-
So, what we want to do here is to use the historical data of some cars, using one or
more of their features, and from that data, make a model.
We use regression to build such a regression/estimation model.
Then the model is used to predict the expected Co2 emission for a new or unknown car.
--
TYPES Of REGRESSION--

Basically there are 2 types of regression models: simple regression and multiple regression.
Simple regression is when one independent variable is used to estimate a dependent variable.
It can be either linear on non-linear.
For example, predicting Co2emission using the variable of EngineSize.
Linearity of regression is based on the nature of relationship between independent and dependent
variables.

When more than one independent variable is present, the process is called multiple linear
regression.

For example, predicting Co2emission using EngineSize and the number of Cylinders in
any given car.

Again, depending on the relation between dependent and independent variables, it can be either
linear or non-linear regression.


-use-
Essentially, we use regression when we want to estimate a continuous value.

-
You can try to predict a salesperson's total yearly sales from independent variables such
as age, education, and years of experience.
It can also be used in the field of psychology, for example, to determine individual satisfaction
based on demographic and psychological factors.
We can use regression analysis to predict the price of a house in an area, based on its
size, number of bedrooms, and so on.
We can even use it to predict employment income for independent variables, such as hours of
work, education, occupation, sex, age, years of experience, and so on.

We have many regression algorithms.
Each of them has its own importance and a specific condition to which their application
is best suited.

-------------------------------------------------------------------------
3.Simple Linear Regression::

The question is: Given this dataset, can we
predict the Co2 emission of a car, using another field, such as Engine size?
Quite simply, yes! We can use linear regression to predict a
continuous value such as Co2 Emission, by using other variables.

-Definition-Linear regression is the approximation of a linear model used to describe the relationship
between two or more variables. In simple linear regression, there are two
variables: a dependent variable and an independent variable.

-The key point- in the linear regression is that our dependent value should be continuous
and cannot be a discreet value. However, the independent variable(s) can be
measured on either a categorical or continuous measurement scale.

#TYPES OF REGRESSION--
There are two types of linear regression models. They are: 
3.1.-simple regression and 
3.2-multiple regression.

3.1-Simple linear regression is when one independent variable is used to estimate
a dependent variable. 
For example, predicting Co2 emission using
the EngineSize variable.

3.2-When more than one independent variable is
present, the process is called multiple linear regression.
For example, predicting Co2 emission using EngineSize and Cylinders of cars.


----
Simple linear gegression---

To understand linear regression, we can plot our variables here.
We show Engine size as an independent variable, and Emission as the target value that we would
like to predict. A scatterplot clearly shows the relation between
variables where changes in one variable "explain" or possibly "cause" changes in the other variable.
Also, it indicates that these variables are linearly related.
With linear regression you can fit a line through the data.
For instance, as the EngineSize increases, so do the emissions.
With linear regression, you can model the relationship of these variables.
A good model can be used to predict what the approximate emission of each car is.
How do we use this line for prediction now? Let us assume, for a moment, that the line
is a good fit of data. We can use it to predict the emission of an
unknown car. For example, for a sample car, with engine
size 2.4, you can find the emission is 214.

--
Now, let’s talk about what this fitting line actually is.
We’re going to predict the target value, y.
In our case, using the independent variable, "Engine Size," represented by x1.
The fit line is shown traditionally as a polynomial. In a simple regression problem (a single x),
the form of the model would be θ0 +θ1 x1. In this equation, y ̂ is the dependent variable
or the predicted value, and x1 is the independent variable; θ0 and θ1 are the parameters of
the line that we must adjust. θ1 is known as the "slope" or "gradient"
of the fitting line and θ0 is known as the "intercept."
θ0 and θ1 are also called the coefficients of the linear equation.
You can interpret this equation as y ̂ being a function of x1, or y ̂ being dependent of x1.
Now the questions are: "How would you draw
a line through the points?" And, "How do you determine which line ‘fits
best’?"
Linear regression estimates the coefficients of the line.
This means we must calculate θ0 and θ1 to find the best line to ‘fit’ the data.
This line would best estimate the emission of the unknown data points.
Let’s see how we can find this line, or to be more precise, how we can adjust the
parameters to make the line the best fit for the data.
For a moment, let’s assume we’ve already found the best fit line for our data.
Now, let’s go through all the points and check how well they align with this line.
Best fit, here, means that if we have, for instance, a car with engine size x1=5.4, and
actual Co2=250, its Co2 should be predicted very close to the actual value, which is y=250,
based on historical data.
But, if we use the fit line, or better to say, using our polynomial with known parameters
to predict the Co2 emission, it will return y ̂ =340.
Now, if you compare the actual value of the emission of the car with what we predicted
using our model, you will find out that we have a 90-unit error.

-This means our prediction line is not accurate. This error is also called the residual error.
So, we can say the error is the distance from the data point to the fitted regression line.
The mean of all residual errors shows how poorly the line fits with the whole dataset.

-Accuracy--
Mathematically, it can be shown by the equation, mean squared error, shown as (MSE).
Our objective is to find a line where the mean of all these errors is minimized.
In other words, the mean error of the prediction using the fit line should be minimized.
Let’s re-word it more technically. The objective of linear regression is to minimize
this MSE equation, and to minimize it, we should find the best parameters, θ0 and θ1.
Now, the question is, how to find θ0 and θ1 in such a way that it minimizes this error?
How can we find such a perfect line? Or, said another way, how should we find the
best parameters for our line? Should we move the line a lot randomly and
calculate the MSE value every time, and choose the minimum one?
